citation: "@inproceedings{jiang2023vima,\n  title     = {VIMA: General Robot Manipulation\
  \ with Multimodal Prompts},\n  author    = {Yunfan Jiang and Agrim Gupta and Zichen\
  \ Zhang and Guanzhi Wang and Yongqiang Dou and Yanjun Chen and Li Fei-Fei and Anima\
  \ Anandkumar and Yuke Zhu and Linxi Fan},\n  booktitle = {Fortieth International\
  \ Conference on Machine Learning},\n  year      = {2023}\n}"
copyright: Copyright
curation:
- open_x_embodiment: true
dataset_name: VIMA
description: The robot is conditioned on multimodal prompts (mixture of texts, images,
  and video frames) to conduct tabletop manipulation tasks, ranging from rearrangement
  to one-shot imitation.
download: []
level_of_support: 0
link: TODO
number_of_trajectories:
- train: 3331523
- test: 3774
schema:
- TODO: schema_todo
size_in_gb: 1390.0
tag:
- Open-X-Embodiment
- Single Arm
- Scripted
- Scene:Table Top
version: 0.0.0
