citation: "@inproceedings{gupta2022maskvit,\n  title={MaskViT: Masked Visual Pre-Training\
  \ for Video Prediction},\n  author={Agrim Gupta and Stephen Tian and Yunzhi Zhang\
  \ and Jiajun Wu and Roberto Mart\xEDn-Mart\xEDn and Li Fei-Fei},\n  booktitle={International\
  \ Conference on Learning Representations},\n  year={2022}\n}"
copyright: Copyright
curation:
- open_x_embodiment: true
dataset_name: Stanford MaskVIT Data
description: The robot randomly pushes and picks objects in a bin, which include stuffed
  toys, plastic cups and toys, etc, and are periodically shuffled.
download:
- link: gs://gresearch/robotics/stanford_mask_vit_converted_externally_to_rlds/0.1.0
  source: google_bucket
level_of_support: 4
link: TODO
number_of_trajectories:
- train: 9109
- val: 91
schema:
- TODO: schema_todo
size_in_gb: 76.17
tag:
- Open-X-Embodiment
- Single Arm
- Scripted
- Scene:Table Top
version: 0.1.0
