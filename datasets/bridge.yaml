citation: "@inproceedings{walke2023bridgedata,\n    title={BridgeData V2: A Dataset\
  \ for Robot Learning at Scale},\n    author={Walke, Homer and Black, Kevin and Lee,\
  \ Abraham and Kim, Moo Jin and Du, Max and Zheng, Chongyi and Zhao, Tony and Hansen-Estruch,\
  \ Philippe and Vuong, Quan and He, Andre and Myers, Vivek and Fang, Kuan and Finn,\
  \ Chelsea and Levine, Sergey},\n    booktitle={Conference on Robot Learning (CoRL)},\n\
  \    year={2023}\n}"
copyright: Copyright
curation:
- open_x_embodiment: true
dataset_name: Berkeley Bridge
description: 'The robot interacts with household environments including kitchens,
  sinks, and tabletops. Skills include object rearrangement, sweeping, stacking, folding,
  and opening/closing doors and drawers. '
download:
- link: gs://gresearch/robotics/bridge/0.1.0
  source: google_bucket
level_of_support: 4
link: TODO
number_of_trajectories:
- train: 25460
- test: 3475
schema:
- TODO: schema_todo
size_in_gb: 387.49
tag:
- Open-X-Embodiment
- Single Arm
- Human VR
- Scene:Table Top
- Scene:Kitchen (also toy kitchen)
- Scene:Other Household environments
version: 0.1.0
