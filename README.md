# Open Robot Datasets

## Datasets 

| dataset_name                    | tag                                                                                                                                                                                                                                     | description                                                                                                                                                                                                                                                                                                                                         | download                                                                                                                             | number_of_trajectories               |
|:--------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------|
| SPOC                            | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Kitchen', 'Scene:Other Household environments', 'Scene:Hallways', 'Scene:multi room environments']                                                                               | The robot navigates in the environment and performs pick and place with open vocabulary descriptions.                                                                                                                                                                                                                                               | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| Berkeley MVP Data               | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | Basic motor control tasks (reach, push, pick) on table top and toy environments (toy kitchen, toy fridge).                                                                                                                                                                                                                                          | [{'link': 'gs://gresearch/robotics/berkeley_mvp_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                     | [{'train': 480}]                     |
| Berkeley Fanuc Manipulation     | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | A Fanuc robot performs various manipulation tasks. For example, it opens drawers, picks up objects, closes doors, closes computers, and pushes objects to desired locations.                                                                                                                                                                        | [{'link': 'gs://gresearch/robotics/berkeley_fanuc_manipulation/0.1.0', 'source': 'google_bucket'}]                                   | [{'train': 415}]                     |
| Berkeley Cable Routing          | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | The robot routes cable through a number of tight-fitting clips mounted on the table.                                                                                                                                                                                                                                                                | [{'link': 'gs://gresearch/robotics/berkeley_cable_routing/0.1.0', 'source': 'google_bucket'}]                                        | [{'train': 1482}, {'test': 165}]     |
| Austin VIOLA                    | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | The robot performs various household-like tasks, such as setting up the table, or making coffee using a coffee machine.                                                                                                                                                                                                                             | [{'link': 'gs://gresearch/robotics/viola/0.1.0', 'source': 'google_bucket'}]                                                         | [{'train': 135}, {'test': 15}]       |
| CMU Franka Exploration          | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Kitchen']                                                                                                                                                                   | Franka exploring kitchen environment, lifting knife and vegetable and opening cabinet.                                                                                                                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/cmu_franka_exploration_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]   | [{'train': 199}]                     |
| ConqHose                        | ['Open-X-Embodiment', 'Mobile Manipulator', 'Scripted', 'Scene:Other Household environments', 'Scene:Hallways']                                                                                                                         | The robot grabs, lifts, and drags the end of a vacuum hose around in an office environment.                                                                                                                                                                                                                                                         | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| KAIST Nonprehensile Objects     | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top']                                                                                                                                                                 | The robot performs various non-prehensile manipulation tasks in a tabletop environment. It translates and reorients diverse real-world and 3d-printed objects to a target 6dof pose.                                                                                                                                                                | [{'link': 'gs://gresearch/robotics/kaist_nonprehensile_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]              | [{'train': 201}]                     |
| CMU Franka Pick-Insert Data     | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | The robot tries to pick up different shaped objects placed in front of it. It also tries to insert particular objects into a cylindrical peg.                                                                                                                                                                                                       | [{'link': 'gs://gresearch/robotics/iamlab_cmu_pickup_insert_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]         | [{'train': 631}]                     |
| Stanford MaskVIT Data           | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | The robot randomly pushes and picks objects in a bin, which include stuffed toys, plastic cups and toys, etc, and are periodically shuffled.                                                                                                                                                                                                        | [{'link': 'gs://gresearch/robotics/stanford_mask_vit_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                | [{'train': 9109}, {'val': 91}]       |
| Austin Sailor                   | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                          | The robot interacts with diverse objects in a toy kitchen. It picks and places food items, a pan, and pot.                                                                                                                                                                                                                                          | [{'link': 'gs://gresearch/robotics/austin_sailor_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]            | [{'train': 240}]                     |
| MimicPlay                       | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | The robot interacts with various appliances in five different scenes, including a kitchen with an oven; a study desk with a bookshelf and lamp; flowers and a vase; toy sandwich making; and cloth folding. It opens the microwave and drawers; places a book on the shelf; inserts a flower into the vase; and assembles a sandwich.               | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| USC Cloth Sim                   | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | The robot manipulates a deformable object (cloth on a tabletop) along a diagonal.                                                                                                                                                                                                                                                                   | [{'link': 'gs://gresearch/robotics/usc_cloth_sim_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                    | [{'train': 800}, {'val': 200}]       |
| Berkeley Bridge                 | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)', 'Scene:Other Household environments']                                                                                            | The robot interacts with household environments including kitchens, sinks, and tabletops. Skills include object rearrangement, sweeping, stacking, folding, and opening/closing doors and drawers.                                                                                                                                                  | [{'link': 'gs://gresearch/robotics/bridge/0.1.0', 'source': 'google_bucket'}]                                                        | [{'train': 25460}, {'test': 3475}]   |
| SACSoN                          | ['Open-X-Embodiment', 'Wheeled Robot', 'Expert Policy', 'Scene:Hallways']                                                                                                                                                               | Mobile robot navigates pedestrian-rich environments (e.g. offices, school buildings etc.) and runs a learned policy that may interact with the pedestrians.                                                                                                                                                                                         | [{'link': 'gs://gresearch/robotics/berkeley_gnm_sac_son/0.1.0', 'source': 'google_bucket'}]                                          | [{'train': 2955}]                    |
| TidyBot                         | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human writes preferred object placements in text form', 'Scene:Kitchen', 'Scene:Other Household environments', 'Scene:living room', 'Scene:bedroom', 'Scene:kitchen', 'Scene:pantry room'] | The robot puts each object into the appropriate receptacle based on user preferences                                                                                                                                                                                                                                                                | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| DLR Wheelchair Shared Control   | ['Open-X-Embodiment', 'Single Arm', 'Human teleoperation using Shared Control Templates', 'Scene:Table Top', 'Scene:shelf']                                                                                                             | The robot grasps a set of different objects in a table top and a shelf.                                                                                                                                                                                                                                                                             | [{'link': 'gs://gresearch/robotics/dlr_edan_shared_control_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]          | [{'train': 104}]                     |
| Stanford HYDRA                  | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | The robot performs the following tasks in corresponding environment: making a cup of coffee using the keurig machine; making a toast using the oven; sorting dishes onto the dish rack.                                                                                                                                                             | [{'link': 'gs://gresearch/robotics/stanford_hydra_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]           | [{'train': 570}]                     |
| DLR Sara Pour Dataset           | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top', 'Scene:Household objects']                                                                                                                                      | The robot learns to pour ping-pong balls from a cup held in the end-effector into the cup placed on the table.                                                                                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/dlr_sara_pour_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                    | [{'train': 100}]                     |
| NYU Franka Play                 | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Kitchen']                                                                                                                                                                        | The robot interacts with a toy kitchen doing arbitrary tasks. It opens/closes the microwave door, opens/closes the oven door, turns the stove knobs, and moves the pot between the stove and the sink.                                                                                                                                              | [{'link': 'gs://gresearch/robotics/nyu_franka_play_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]          | [{'train': 365}, {'val': 91}]        |
| CMU Stretch                     | ['Open-X-Embodiment', 'Mobile Manipulator', 'Expert Policy', 'Scene:Kitchen', 'Scene:Other Household environments']                                                                                                                     | Robot interacting with different household environments.                                                                                                                                                                                                                                                                                            | [{'link': 'gs://gresearch/robotics/cmu_stretch/0.1.0', 'source': 'google_bucket'}]                                                   | [{'train': 135}]                     |
| Berkeley RPT Data               | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | Picking, stacking, destacking, and bin picking with variations in objects.                                                                                                                                                                                                                                                                          | [{'link': 'gs://gresearch/robotics/berkeley_rpt_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                     | [{'train': 908}]                     |
| CMU Play Fusion                 | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | The robot plays with 3 complex scenes: a grill with many cooking objects like toaster, pan, etc. It has to pick, open, place, close. It  has to set a table, move plates, cups, utensils. And it has to place dishes in the sink, dishwasher, hand cups etc.                                                                                        | [{'link': 'gs://gresearch/robotics/cmu_play_fusion/0.1.0', 'source': 'google_bucket'}]                                               | [{'train': 576}]                     |
| UTokyo xArm Bimanual            | ['Open-X-Embodiment', 'Bi-Manual', 'Human Puppeteering', 'Scene:Table Top']                                                                                                                                                             | The robots reach a towel on the table. They also unfold a wrinkled towel.                                                                                                                                                                                                                                                                           | [{'link': 'gs://gresearch/robotics/utokyo_xarm_bimanual_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]             | [{'train': 64}, {'val': 6}]          |
| DLR Sara Grid Clamp Dataset     | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top', 'Scene:Workshop environment']                                                                                                                                   | The robot learns to place the grid clamp in the grids on the table.                                                                                                                                                                                                                                                                                 | [{'link': 'gs://gresearch/robotics/dlr_sara_grid_clamp_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]              | [{'train': 107}]                     |
| CMU Food Manipulation           | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | Robot interacting with different food items.                                                                                                                                                                                                                                                                                                        | []                                                                                                                                   | [{'train': 415}]                     |
| Berkeley Autolab UR5            | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | The data consists of 4 robot manipulation tasks: simple pick-and-place of a stuffed animal between containers, sweeping a cloth, stacking cups, and a more difficult pick-and-place of a bottle that requires precise grasp and 6DOF rotation                                                                                                       | [{'link': 'gs://gresearch/robotics/berkeley_autolab_ur5/0.1.0', 'source': 'google_bucket'}]                                          | [{'train': 896}, {'test': 104}]      |
| Saytap                          | ['Open-X-Embodiment', 'Quadrupedal Robot', 'Expert Policy', 'Scene:Indoor', 'Scene:on a flat floor']                                                                                                                                    | A Unitree Go1 robot follows human command in natural language (e.g., "trot forward slowly")                                                                                                                                                                                                                                                         | [{'link': 'gs://gresearch/robotics/utokyo_saytap_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                    | [{'train': 20}]                      |
| QT-Opt                          | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top']                                                                                                                                                                 | Kuka robot picking objects in a bin.                                                                                                                                                                                                                                                                                                                | [{'link': 'gs://gresearch/robotics/kuka/0.1.0', 'source': 'google_bucket'}]                                                          | [{'train': 580392}]                  |
| TOTO Benchmark                  | ['Open-X-Embodiment', 'Single Arm', 'The dataset is collected in 3 ways: Human teleoperation -- VR Teleop, trained state-based BC policies, and trajectory replay with noise', 'Scene:Table Top']                                       | The TOTO Benchmark Dataset contains trajectories of two tasks: scooping and pouring. For scooping, the objective is to scoop material from a bowl into the spoon. For pouring, the goal is to pour some material into a target cup on the table.                                                                                                    | [{'link': 'gs://gresearch/robotics/toto/0.1.0', 'source': 'google_bucket'}]                                                          | [{'train': 902}, {'test': 101}]      |
| LSMO Dataset                    | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top']                                                                                                                                                                 | The robot avoids obstacle on the table and reaches the target object.                                                                                                                                                                                                                                                                               | [{'link': 'gs://gresearch/robotics/tokyo_u_lsmo_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                     | [{'train': 50}]                      |
| FMB                             | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | The robot interacts with diverse 3D printed objects, pick them up, reposition, and assemble them                                                                                                                                                                                                                                                    | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| Stanford Robocook               | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | In the first task, the robot pinches the dough with an asymmetric gripper / two-rod symmetric gripper / two-plane symmetric gripper. In the second task, the robot presses the dough with a circle press / square press / circle punch / square punch. In the third task, the robot rolls the dough with a large roller / small roller.             | [{'link': 'gs://gresearch/robotics/stanford_robocook_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                | [{'train': 2460}]                    |
| CoryHall                        | ['Open-X-Embodiment', 'Wheeled Robot', 'Expert Policy', 'Scene:Hallways']                                                                                                                                                               | Small mobile robot navigates hallways in an office building using a learned policy.                                                                                                                                                                                                                                                                 | [{'link': 'gs://gresearch/robotics/berkeley_gnm_cory_hall/0.1.0', 'source': 'google_bucket'}]                                        | [{'train': 7331}]                    |
| MPI Muscular Proprioception     | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:The robot is alone in the environment', 'Scene:there are no other objects in the workspace.']                                                                                    | There is no task that the robot solves. It executes a combination of random multisine signals of target pressures, as well as fixed target pressures.                                                                                                                                                                                               | []                                                                                                                                   | [{'train': 631}]                     |
| Columbia PushT Dataset          | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | The robot pushes a T-shaped block into a fixed goal pose, and then move to an fixed exit zone.                                                                                                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/columbia_cairlab_pusht_real/0.1.0', 'source': 'google_bucket'}]                                   | [{'train': 122}, {'test': 14}]       |
| RoboSet                         | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)', 'Scene:Other Household environments']                                                                                            | "The robot interacts with different objects in kitchen scenes. It performs articulated object manipulation of objects with prismatic joints and hinges. It wipes tables with cloth. It performs pick and place skills, and skills requiring precision like capping and uncapping."                                                                  | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| Furniture Bench                 | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | The robot assembles one of 9 3D-printed furniture models on the table, which requires grasping, inserting, and screwing.                                                                                                                                                                                                                            | [{'link': 'gs://gresearch/robotics/furniture_bench_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]          | [{'train': 5100}]                    |
| MobileALOHA                     | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human Puppeteering', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)', 'Scene:Other Household environments', 'Scene:Hallways']                                                        | The robot interacts with diverse appliances in a real kitchen and indoor environments. It wipes spilled wine, stores a heavy pot to be inside wall cabinets, calls an elevator, pushes chairs, and cooks shrimp.                                                                                                                                    | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| Tokyo PR2 Fridge Opening        | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Kitchen']                                                                                                                                                                        | The PR2 robot opens fridge.                                                                                                                                                                                                                                                                                                                         | [{'link': 'gs://gresearch/robotics/utokyo_pr2_opening_fridge_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]        | [{'train': 64}, {'val': 16}]         |
| USC Jaco Play                   | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | The robot performs pick-place tasks in a tabletop toy kitchen environment. Some examples of the task include, "Pick up the orange fruit.", "Put the black bowl in the sink."                                                                                                                                                                        | [{'link': 'gs://gresearch/robotics/jaco_play/0.1.0', 'source': 'google_bucket'}]                                                     | [{'train': 976}, {'test': 109}]      |
| ALOHA                           | ['Open-X-Embodiment', 'Bi-Manual', 'Human Puppeteering', 'Scene:Table Top']                                                                                                                                                             | Bi-manual robot performing complex, dexterous tasks like unwrapping candy and putting on shoes.                                                                                                                                                                                                                                                     | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| QUT Dexterous Manpulation       | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human VR', 'Scene:Table Top']                                                                                                                                                              | The robot performs some tasks in a tabletop setting. It sorts dishes and objects, cooks and serves food, sets the table, throws away trash paper, rolls dices, waters plants, stacks toy blocks.                                                                                                                                                    | []                                                                                                                                   | [{'train': 631}]                     |
| BC-Z                            | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human VR', 'Scene:Table Top']                                                                                                                                                              | The robot attempts picking, wiping, and placing tasks on a diverse set of objects on a tabletop, along with a few challenging tasks like stacking cups on top of each other.                                                                                                                                                                        | [{'link': 'gs://gresearch/robotics/bc_z/0.1.0', 'source': 'google_bucket'}]                                                          | [{'train': 39350}, {'val': 3914}]    |
| NYU VINN                        | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human Kinesthetic', 'Scene:Kitchen', 'Scene:Other Household environments']                                                                                                                 | The robot opens cabinet doors for a variety of cabinets.                                                                                                                                                                                                                                                                                            | [{'link': 'gs://gresearch/robotics/nyu_door_opening_surprising_effectiveness/0.1.0', 'source': 'google_bucket'}]                     | [{'train': 435}, {'test': 49}]       |
| UIUC D3Field                    | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | The robot completes tasks specified by the goal image, including organizing utensils, shoes, mugs.                                                                                                                                                                                                                                                  | [{'link': 'gs://gresearch/robotics/uiuc_d3field/0.1.0', 'source': 'google_bucket'}]                                                  | [{'train': 192}]                     |
| Robonet                         | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | The robot interacts with the objects in a bin placed in front of it                                                                                                                                                                                                                                                                                 | [{'link': 'gs://gresearch/robotics/robo_net/1.0.0', 'source': 'google_bucket'}]                                                      | [{'train': 82775}]                   |
| Maniskill                       | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | The robot interacts with different objects placed on the plane (ground). The tasks include picking an isolated object or an object from the clutter up and moving it to a goal position, stacking a red cube onto a green cube, inserting a peg into the box, assembling kits, plugging a charger into the outlet on the wall, turning on a faucet. | [{'link': 'gs://gresearch/robotics/maniskill_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                | [{'train': 30213}]                   |
| NYU ROT                         | ['Open-X-Embodiment', 'Single Arm', 'Human Joystick', 'Scene:Table Top']                                                                                                                                                                | The robot arm performs diverse manipulation tasks on a tabletop such an box opening, cup stacking, and pouring, among others.                                                                                                                                                                                                                       | [{'link': 'gs://gresearch/robotics/nyu_rot_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                  | [{'train': 14}]                      |
| Freiburg Franka Play            | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | "The robot interacts with toy blocks, it pick and places them, stacks them, unstacks them, opens drawers, sliding doors and turrns on LED lights by pushing buttons."                                                                                                                                                                               | [{'link': 'gs://gresearch/robotics/taco_play/0.1.0', 'source': 'google_bucket'}]                                                     | [{'train': 3242}, {'test': 361}]     |
| Tokyo PR2 Tabletop Manipulation | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | The PR2 robot conducts manipulation for table top object. It conducts pick-and-place of bread and grape and folds cloth.                                                                                                                                                                                                                            | [{'link': 'gs://gresearch/robotics/utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}] | [{'train': 192}, {'val': 48}]        |
| Plex RoboSuite                  | ['Open-X-Embodiment', 'Single Arm', 'Human Keyboard', 'Scene:Table Top', 'Scene:Tabletop with sections']                                                                                                                                | Opening a door, stacking 2 cubes, picking and placing various objects to specially designated areas, putting a loop onto a peg.                                                                                                                                                                                                                     | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| Austin Sirius                   | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | The dataset comprises two tasks, kcup and gear. The kcup task requires opening the kcup holder, inserting the kcup into the holder, and closing the holder. The gear task requires inserting the blue gear onto the right peg, followed by inserting the smaller red gear.                                                                          | [{'link': 'gs://gresearch/robotics/austin_sirius_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]            | [{'train': 559}]                     |
| DROID                           | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)', 'Scene:Other Household environments', 'Scene:Hallways']                                                                          | Various household manipulation tasks                                                                                                                                                                                                                                                                                                                | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| DobbE                           | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human collection using tools', 'Scene:Kitchen', 'Scene:Other Household environments', 'Scene:Hallways']                                                                                    | The demo collector uses the Stick to collect data from 7 tasks, including door/drawer opening/closing, handle grasping, pick and place, and random play data.                                                                                                                                                                                       | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| UCSD Kitchen                    | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Kitchen']                                                                                                                                                                        | The dataset offers a comprehensive set of real-world robotic interactions, involving natural language instructions and complex manipulations with kitchen objects.                                                                                                                                                                                  | [{'link': 'gs://gresearch/robotics/ucsd_kitchen_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]             | [{'train': 150}]                     |
| ETH Agent Affordances           | ['Open-X-Embodiment', 'Mobile Manipulator', 'Expert Policy', 'Scene:Kitchen']                                                                                                                                                           | The robot opens and closes an oven, starting from different initial positions and door angles.                                                                                                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/eth_agent_affordances/0.1.0', 'source': 'google_bucket'}]                                         | [{'train': 118}]                     |
| UCSD Pick Place                 | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                             | The robot performs pick and place tasks in table top and kitchen scenes. The dataset contains a variety of visual variations.                                                                                                                                                                                                                       | [{'link': 'gs://gresearch/robotics/ucsd_pick_and_place_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]      | [{'train': 1355}]                    |
| RT-1 Robot Action               | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                          | Robot picks, places and moves 17 objects from the google micro kitchens.                                                                                                                                                                                                                                                                            | [{'link': 'gs://gresearch/robotics/fractal20220817_data/0.1.0', 'source': 'google_bucket'}]                                          | [{'train': 87212}]                   |
| Roboturk                        | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | Sawyer robots flattens laundry, builds towers from bowls and searches objects.                                                                                                                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/roboturk/0.1.0', 'source': 'google_bucket'}]                                                      | [{'train': 1796}, {'test': 199}]     |
| UTokyo xArm PickPlace           | ['Open-X-Embodiment', 'Single Arm', 'Human Puppeteering', 'Scene:Table Top']                                                                                                                                                            | The robot picks up a white plate, and then places it on the red plate.                                                                                                                                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/utokyo_xarm_pick_and_place_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]       | [{'train': 92}, {'val': 10}]         |
| Language Table                  | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | Robot pushed blocks of different geometric shapes on table top.                                                                                                                                                                                                                                                                                     | [{'link': 'gs://gresearch/robotics/language_table/0.0.1', 'source': 'google_bucket'}]                                                | [{'train': 442226}]                  |
| VIMA                            | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | The robot is conditioned on multimodal prompts (mixture of texts, images, and video frames) to conduct tabletop manipulation tasks, ranging from rearrangement to one-shot imitation.                                                                                                                                                               | []                                                                                                                                   | [{'train': 3331523}, {'test': 3774}] |
| QUT Dynamic Grasping            | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | The robot grasps an object that moves around continuously and randomly along the XY plane.                                                                                                                                                                                                                                                          | []                                                                                                                                   | [{'train': 201}]                     |
| RECON                           | ['Open-X-Embodiment', 'Wheeled Robot', 'Scripted', 'Scene:Outdoors']                                                                                                                                                                    | Mobile robot explores outdoor environments using a scripted policy                                                                                                                                                                                                                                                                                  | [{'link': 'gs://gresearch/robotics/berkeley_gnm_recon/0.1.0', 'source': 'google_bucket'}]                                            | [{'train': 11834}]                   |
| ASU TableTop Manipulation       | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | The robot interacts with a few objects on a table. It picks up, pushes forward, or rotates the objects.                                                                                                                                                                                                                                             | [{'link': 'gs://gresearch/robotics/asu_table_top_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                    | [{'train': 110}]                     |
| Austin Mutex                    | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | The Mutex dataset involves a diverse range of tasks in a home environment, encompassing pick and place tasks like "putting bread on a plate," as well as contact-rich tasks such as "opening an air fryer and putting a bowl with dogs in it" or "taking out a tray from the oven and placing bread on it."                                         | [{'link': 'gs://gresearch/robotics/utaustin_mutex/0.1.0', 'source': 'google_bucket'}]                                                | [{'train': 1500}]                    |
| Austin BUDS                     | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | The robot is trying to solve a long-horizon kitchen task by picking up pot, placing the pot in a plate, and push them together using a picked-up tool.                                                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/austin_buds_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]              | [{'train': 50}]                      |
| Stanford Kuka Multimodal        | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top']                                                                                                                                                                 | The robot learns to insert differently-shaped pegs into differently-shaped holes with low tolerances (~2mm).                                                                                                                                                                                                                                        | [{'link': 'gs://gresearch/robotics/stanford_kuka_multimodal_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}] | [{'train': 3000}]                    |

## Contributing

Explain how to contribute here.


## License 

The curated list is under CC0-1.0 License. Please refer to specific dataset for licensing terms. 
