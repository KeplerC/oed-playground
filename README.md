
# Open Embodiment Datasets

This is an auto-generated README file at time 2024-06-20 06:11:57

## Dataset 

| dataset_name                    | description                                                                                                                                                                                                                                                                                                                                         | tag                                                                                                                                                                                                                                     | download                                                                                                                             | curation                      | intended_level_of_support   | copyright   | number_of_trajectories               |   size_in_gb |
|:--------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------------------------------------------------------------------------------------------------------------------------------|:------------------------------|:----------------------------|:------------|:-------------------------------------|-------------:|
| CoryHall                        | Small mobile robot navigates hallways in an office building using a learned policy.                                                                                                                                                                                                                                                                 | ['Open-X-Embodiment', 'Wheeled Robot', 'Expert Policy', 'Scene:Hallways']                                                                                                                                                               | [{'link': 'gs://gresearch/robotics/berkeley_gnm_cory_hall/0.1.0', 'source': 'google_bucket'}]                                        | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 7331}]                    |         1.39 |
| Austin Sirius                   | The dataset comprises two tasks, kcup and gear. The kcup task requires opening the kcup holder, inserting the kcup into the holder, and closing the holder. The gear task requires inserting the blue gear onto the right peg, followed by inserting the smaller red gear.                                                                          | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/austin_sirius_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]            | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 559}]                     |         6.55 |
| Tokyo PR2 Tabletop Manipulation | The PR2 robot conducts manipulation for table top object. It conducts pick-and-place of bread and grape and folds cloth.                                                                                                                                                                                                                            | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/utokyo_pr2_tabletop_manipulation_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}] | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 192}, {'val': 48}]        |         0.81 |
| CMU Stretch                     | Robot interacting with different household environments.                                                                                                                                                                                                                                                                                            | ['Open-X-Embodiment', 'Mobile Manipulator', 'Expert Policy', 'Scene:Kitchen', 'Scene:Other Household environments']                                                                                                                     | [{'link': 'gs://gresearch/robotics/cmu_stretch/0.1.0', 'source': 'google_bucket'}]                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 135}]                     |         0.71 |
| QT-Opt                          | Kuka robot picking objects in a bin.                                                                                                                                                                                                                                                                                                                | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top']                                                                                                                                                                 | [{'link': 'gs://gresearch/robotics/kuka/0.1.0', 'source': 'google_bucket'}]                                                          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 580392}]                  |       778.02 |
| DobbE                           | The demo collector uses the Stick to collect data from 7 tasks, including door/drawer opening/closing, handle grasping, pick and place, and random play data.                                                                                                                                                                                       | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human collection using tools', 'Scene:Kitchen', 'Scene:Other Household environments', 'Scene:Hallways']                                                                                    | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |        21.1  |
| UCSD Pick Place                 | The robot performs pick and place tasks in table top and kitchen scenes. The dataset contains a variety of visual variations.                                                                                                                                                                                                                       | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                             | [{'link': 'gs://gresearch/robotics/ucsd_pick_and_place_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]      | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 1355}]                    |         3.53 |
| Stanford MaskVIT Data           | The robot randomly pushes and picks objects in a bin, which include stuffed toys, plastic cups and toys, etc, and are periodically shuffled.                                                                                                                                                                                                        | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/stanford_mask_vit_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 9109}, {'val': 91}]       |        76.17 |
| QUT Dynamic Grasping            | The robot grasps an object that moves around continuously and randomly along the XY plane.                                                                                                                                                                                                                                                          | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 201}]                     |       nan    |
| DLR Sara Grid Clamp Dataset     | The robot learns to place the grid clamp in the grids on the table.                                                                                                                                                                                                                                                                                 | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top', 'Scene:Workshop environment']                                                                                                                                   | [{'link': 'gs://gresearch/robotics/dlr_sara_grid_clamp_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]              | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 107}]                     |         1.65 |
| CMU Franka Pick-Insert Data     | The robot tries to pick up different shaped objects placed in front of it. It also tries to insert particular objects into a cylindrical peg.                                                                                                                                                                                                       | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/iamlab_cmu_pickup_insert_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]         | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 631}]                     |        50.29 |
| NYU ROT                         | The robot arm performs diverse manipulation tasks on a tabletop such an box opening, cup stacking, and pouring, among others.                                                                                                                                                                                                                       | ['Open-X-Embodiment', 'Single Arm', 'Human Joystick', 'Scene:Table Top']                                                                                                                                                                | [{'link': 'gs://gresearch/robotics/nyu_rot_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                  | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 14}]                      |         0.01 |
| UTokyo xArm Bimanual            | The robots reach a towel on the table. They also unfold a wrinkled towel.                                                                                                                                                                                                                                                                           | ['Open-X-Embodiment', 'Bi-Manual', 'Human Puppeteering', 'Scene:Table Top']                                                                                                                                                             | [{'link': 'gs://gresearch/robotics/utokyo_xarm_bimanual_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]             | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 64}, {'val': 6}]          |         0.14 |
| ALOHA                           | Bi-manual robot performing complex, dexterous tasks like unwrapping candy and putting on shoes.                                                                                                                                                                                                                                                     | ['Open-X-Embodiment', 'Bi-Manual', 'Human Puppeteering', 'Scene:Table Top']                                                                                                                                                             | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |       nan    |
| QUT Dexterous Manpulation       | The robot performs some tasks in a tabletop setting. It sorts dishes and objects, cooks and serves food, sets the table, throws away trash paper, rolls dices, waters plants, stacks toy blocks.                                                                                                                                                    | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human VR', 'Scene:Table Top']                                                                                                                                                              | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 631}]                     |       nan    |
| Columbia PushT Dataset          | The robot pushes a T-shaped block into a fixed goal pose, and then move to an fixed exit zone.                                                                                                                                                                                                                                                      | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/columbia_cairlab_pusht_real/0.1.0', 'source': 'google_bucket'}]                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 122}, {'test': 14}]       |         2.8  |
| FMB                             | The robot interacts with diverse 3D printed objects, pick them up, reposition, and assemble them                                                                                                                                                                                                                                                    | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |       356.5  |
| DROID                           | Various household manipulation tasks                                                                                                                                                                                                                                                                                                                | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)', 'Scene:Other Household environments', 'Scene:Hallways']                                                                          | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |      1670    |
| Stanford Kuka Multimodal        | The robot learns to insert differently-shaped pegs into differently-shaped holes with low tolerances (~2mm).                                                                                                                                                                                                                                        | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top']                                                                                                                                                                 | [{'link': 'gs://gresearch/robotics/stanford_kuka_multimodal_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}] | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3000}]                    |        31.98 |
| DLR Wheelchair Shared Control   | The robot grasps a set of different objects in a table top and a shelf.                                                                                                                                                                                                                                                                             | ['Open-X-Embodiment', 'Single Arm', 'Human teleoperation using Shared Control Templates', 'Scene:Table Top', 'Scene:shelf']                                                                                                             | [{'link': 'gs://gresearch/robotics/dlr_edan_shared_control_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 104}]                     |         3.09 |
| Berkeley Cable Routing          | The robot routes cable through a number of tight-fitting clips mounted on the table.                                                                                                                                                                                                                                                                | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/berkeley_cable_routing/0.1.0', 'source': 'google_bucket'}]                                        | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 1482}, {'test': 165}]     |         4.67 |
| VIMA                            | The robot is conditioned on multimodal prompts (mixture of texts, images, and video frames) to conduct tabletop manipulation tasks, ranging from rearrangement to one-shot imitation.                                                                                                                                                               | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |      1390    |
| Stanford HYDRA                  | The robot performs the following tasks in corresponding environment: making a cup of coffee using the keurig machine; making a toast using the oven; sorting dishes onto the dish rack.                                                                                                                                                             | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | [{'link': 'gs://gresearch/robotics/stanford_hydra_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]           | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 570}]                     |        72.48 |
| Tokyo PR2 Fridge Opening        | The PR2 robot opens fridge.                                                                                                                                                                                                                                                                                                                         | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Kitchen']                                                                                                                                                                        | [{'link': 'gs://gresearch/robotics/utokyo_pr2_opening_fridge_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]        | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 64}, {'val': 16}]         |         0.35 |
| Berkeley MVP Data               | Basic motor control tasks (reach, push, pick) on table top and toy environments (toy kitchen, toy fridge).                                                                                                                                                                                                                                          | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | [{'link': 'gs://gresearch/robotics/berkeley_mvp_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                     | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 480}]                     |        12.34 |
| Freiburg Franka Play            | "The robot interacts with toy blocks, it pick and places them, stacks them, unstacks them, opens drawers, sliding doors and turrns on LED lights by pushing buttons."                                                                                                                                                                               | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/taco_play/0.1.0', 'source': 'google_bucket'}]                                                     | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3242}, {'test': 361}]     |        47.77 |
| MPI Muscular Proprioception     | There is no task that the robot solves. It executes a combination of random multisine signals of target pressures, as well as fixed target pressures.                                                                                                                                                                                               | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:The robot is alone in the environment', 'Scene:there are no other objects in the workspace.']                                                                                    | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 631}]                     |       nan    |
| LSMO Dataset                    | The robot avoids obstacle on the table and reaches the target object.                                                                                                                                                                                                                                                                               | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top']                                                                                                                                                                 | [{'link': 'gs://gresearch/robotics/tokyo_u_lsmo_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                     | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 50}]                      |         0.33 |
| RoboSet                         | "The robot interacts with different objects in kitchen scenes. It performs articulated object manipulation of objects with prismatic joints and hinges. It wipes tables with cloth. It performs pick and place skills, and skills requiring precision like capping and uncapping."                                                                  | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)', 'Scene:Other Household environments']                                                                                            | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |       178.65 |
| Austin BUDS                     | The robot is trying to solve a long-horizon kitchen task by picking up pot, placing the pot in a plate, and push them together using a picked-up tool.                                                                                                                                                                                              | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/austin_buds_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]              | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 50}]                      |         1.49 |
| Berkeley Bridge                 | The robot interacts with household environments including kitchens, sinks, and tabletops. Skills include object rearrangement, sweeping, stacking, folding, and opening/closing doors and drawers.                                                                                                                                                  | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)', 'Scene:Other Household environments']                                                                                            | [{'link': 'gs://gresearch/robotics/bridge/0.1.0', 'source': 'google_bucket'}]                                                        | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 25460}, {'test': 3475}]   |       387.49 |
| UIUC D3Field                    | The robot completes tasks specified by the goal image, including organizing utensils, shoes, mugs.                                                                                                                                                                                                                                                  | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/uiuc_d3field/0.1.0', 'source': 'google_bucket'}]                                                  | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 192}]                     |        15.82 |
| CMU Food Manipulation           | Robot interacting with different food items.                                                                                                                                                                                                                                                                                                        | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 415}]                     |       720    |
| ConqHose                        | The robot grabs, lifts, and drags the end of a vacuum hose around in an office environment.                                                                                                                                                                                                                                                         | ['Open-X-Embodiment', 'Mobile Manipulator', 'Scripted', 'Scene:Other Household environments', 'Scene:Hallways']                                                                                                                         | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |         2.71 |
| MobileALOHA                     | The robot interacts with diverse appliances in a real kitchen and indoor environments. It wipes spilled wine, stores a heavy pot to be inside wall cabinets, calls an elevator, pushes chairs, and cooks shrimp.                                                                                                                                    | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human Puppeteering', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)', 'Scene:Other Household environments', 'Scene:Hallways']                                                        | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |        47.83 |
| NYU VINN                        | The robot opens cabinet doors for a variety of cabinets.                                                                                                                                                                                                                                                                                            | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human Kinesthetic', 'Scene:Kitchen', 'Scene:Other Household environments']                                                                                                                 | [{'link': 'gs://gresearch/robotics/nyu_door_opening_surprising_effectiveness/0.1.0', 'source': 'google_bucket'}]                     | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 435}, {'test': 49}]       |         7.12 |
| KAIST Nonprehensile Objects     | The robot performs various non-prehensile manipulation tasks in a tabletop environment. It translates and reorients diverse real-world and 3d-printed objects to a target 6dof pose.                                                                                                                                                                | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top']                                                                                                                                                                 | [{'link': 'gs://gresearch/robotics/kaist_nonprehensile_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]              | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 201}]                     |        11.71 |
| ASU TableTop Manipulation       | The robot interacts with a few objects on a table. It picks up, pushes forward, or rotates the objects.                                                                                                                                                                                                                                             | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/asu_table_top_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                    | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 110}]                     |         0.72 |
| Maniskill                       | The robot interacts with different objects placed on the plane (ground). The tasks include picking an isolated object or an object from the clutter up and moving it to a goal position, stacking a red cube onto a green cube, inserting a peg into the box, assembling kits, plugging a charger into the outlet on the wall, turning on a faucet. | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/maniskill_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 30213}]                   |       151.05 |
| UCSD Kitchen                    | The dataset offers a comprehensive set of real-world robotic interactions, involving natural language instructions and complex manipulations with kitchen objects.                                                                                                                                                                                  | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Kitchen']                                                                                                                                                                        | [{'link': 'gs://gresearch/robotics/ucsd_kitchen_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]             | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 150}]                     |         1.33 |
| Robonet                         | The robot interacts with the objects in a bin placed in front of it                                                                                                                                                                                                                                                                                 | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/robo_net/1.0.0', 'source': 'google_bucket'}]                                                      | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 82775}]                   |       799.91 |
| SACSoN                          | Mobile robot navigates pedestrian-rich environments (e.g. offices, school buildings etc.) and runs a learned policy that may interact with the pedestrians.                                                                                                                                                                                         | ['Open-X-Embodiment', 'Wheeled Robot', 'Expert Policy', 'Scene:Hallways']                                                                                                                                                               | [{'link': 'gs://gresearch/robotics/berkeley_gnm_sac_son/0.1.0', 'source': 'google_bucket'}]                                          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 2955}]                    |         7    |
| Austin Sailor                   | The robot interacts with diverse objects in a toy kitchen. It picks and places food items, a pan, and pot.                                                                                                                                                                                                                                          | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                          | [{'link': 'gs://gresearch/robotics/austin_sailor_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]            | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 240}]                     |        18.85 |
| Austin Mutex                    | The Mutex dataset involves a diverse range of tasks in a home environment, encompassing pick and place tasks like "putting bread on a plate," as well as contact-rich tasks such as "opening an air fryer and putting a bowl with dogs in it" or "taking out a tray from the oven and placing bread on it."                                         | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/utaustin_mutex/0.1.0', 'source': 'google_bucket'}]                                                | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 1500}]                    |        20.79 |
| MimicPlay                       | The robot interacts with various appliances in five different scenes, including a kitchen with an oven; a study desk with a bookshelf and lamp; flowers and a vase; toy sandwich making; and cloth folding. It opens the microwave and drawers; places a book on the shelf; inserts a flower into the vase; and assembles a sandwich.               | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |         7.13 |
| USC Cloth Sim                   | The robot manipulates a deformable object (cloth on a tabletop) along a diagonal.                                                                                                                                                                                                                                                                   | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | [{'link': 'gs://gresearch/robotics/usc_cloth_sim_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                    | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 800}, {'val': 200}]       |         0.25 |
| Language Table                  | Robot pushed blocks of different geometric shapes on table top.                                                                                                                                                                                                                                                                                     | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/language_table/0.0.1', 'source': 'google_bucket'}]                                                | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 442226}]                  |       399.22 |
| UTokyo xArm PickPlace           | The robot picks up a white plate, and then places it on the red plate.                                                                                                                                                                                                                                                                              | ['Open-X-Embodiment', 'Single Arm', 'Human Puppeteering', 'Scene:Table Top']                                                                                                                                                            | [{'link': 'gs://gresearch/robotics/utokyo_xarm_pick_and_place_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]       | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 92}, {'val': 10}]         |         1.29 |
| TidyBot                         | The robot puts each object into the appropriate receptacle based on user preferences                                                                                                                                                                                                                                                                | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human writes preferred object placements in text form', 'Scene:Kitchen', 'Scene:Other Household environments', 'Scene:living room', 'Scene:bedroom', 'Scene:kitchen', 'Scene:pantry room'] | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |         0.02 |
| Berkeley RPT Data               | Picking, stacking, destacking, and bin picking with variations in objects.                                                                                                                                                                                                                                                                          | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/berkeley_rpt_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                     | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 908}]                     |        40.64 |
| CMU Play Fusion                 | The robot plays with 3 complex scenes: a grill with many cooking objects like toaster, pan, etc. It has to pick, open, place, close. It  has to set a table, move plates, cups, utensils. And it has to place dishes in the sink, dishwasher, hand cups etc.                                                                                        | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | [{'link': 'gs://gresearch/robotics/cmu_play_fusion/0.1.0', 'source': 'google_bucket'}]                                               | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 576}]                     |         6.68 |
| NYU Franka Play                 | The robot interacts with a toy kitchen doing arbitrary tasks. It opens/closes the microwave door, opens/closes the oven door, turns the stove knobs, and moves the pot between the stove and the sink.                                                                                                                                              | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Kitchen']                                                                                                                                                                        | [{'link': 'gs://gresearch/robotics/nyu_franka_play_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 365}, {'val': 91}]        |         5.18 |
| RECON                           | Mobile robot explores outdoor environments using a scripted policy                                                                                                                                                                                                                                                                                  | ['Open-X-Embodiment', 'Wheeled Robot', 'Scripted', 'Scene:Outdoors']                                                                                                                                                                    | [{'link': 'gs://gresearch/robotics/berkeley_gnm_recon/0.1.0', 'source': 'google_bucket'}]                                            | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 11834}]                   |        18.73 |
| Stanford Robocook               | In the first task, the robot pinches the dough with an asymmetric gripper / two-rod symmetric gripper / two-plane symmetric gripper. In the second task, the robot presses the dough with a circle press / square press / circle punch / square punch. In the third task, the robot rolls the dough with a large roller / small roller.             | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | [{'link': 'gs://gresearch/robotics/stanford_robocook_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 2460}]                    |       124.62 |
| Saytap                          | A Unitree Go1 robot follows human command in natural language (e.g., "trot forward slowly")                                                                                                                                                                                                                                                         | ['Open-X-Embodiment', 'Quadrupedal Robot', 'Expert Policy', 'Scene:Indoor', 'Scene:on a flat floor']                                                                                                                                    | [{'link': 'gs://gresearch/robotics/utokyo_saytap_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                    | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 20}]                      |         0.05 |
| Furniture Bench                 | The robot assembles one of 9 3D-printed furniture models on the table, which requires grasping, inserting, and screwing.                                                                                                                                                                                                                            | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/furniture_bench_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 5100}]                    |       110    |
| DLR Sara Pour Dataset           | The robot learns to pour ping-pong balls from a cup held in the end-effector into the cup placed on the table.                                                                                                                                                                                                                                      | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Table Top', 'Scene:Household objects']                                                                                                                                      | [{'link': 'gs://gresearch/robotics/dlr_sara_pour_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]                    | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 100}]                     |         2.92 |
| BC-Z                            | The robot attempts picking, wiping, and placing tasks on a diverse set of objects on a tabletop, along with a few challenging tasks like stacking cups on top of each other.                                                                                                                                                                        | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human VR', 'Scene:Table Top']                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/bc_z/0.1.0', 'source': 'google_bucket'}]                                                          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 39350}, {'val': 3914}]    |        80.54 |
| Berkeley Fanuc Manipulation     | A Fanuc robot performs various manipulation tasks. For example, it opens drawers, picks up objects, closes doors, closes computers, and pushes objects to desired locations.                                                                                                                                                                        | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/berkeley_fanuc_manipulation/0.1.0', 'source': 'google_bucket'}]                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 415}]                     |         8.85 |
| CMU Franka Exploration          | Franka exploring kitchen environment, lifting knife and vegetable and opening cabinet.                                                                                                                                                                                                                                                              | ['Open-X-Embodiment', 'Single Arm', 'Expert Policy', 'Scene:Kitchen']                                                                                                                                                                   | [{'link': 'gs://gresearch/robotics/cmu_franka_exploration_dataset_converted_externally_to_rlds/0.1.0', 'source': 'google_bucket'}]   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 199}]                     |         0.59 |
| ETH Agent Affordances           | The robot opens and closes an oven, starting from different initial positions and door angles.                                                                                                                                                                                                                                                      | ['Open-X-Embodiment', 'Mobile Manipulator', 'Expert Policy', 'Scene:Kitchen']                                                                                                                                                           | [{'link': 'gs://gresearch/robotics/eth_agent_affordances/0.1.0', 'source': 'google_bucket'}]                                         | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 118}]                     |        17.27 |
| USC Jaco Play                   | The robot performs pick-place tasks in a tabletop toy kitchen environment. Some examples of the task include, "Pick up the orange fruit.", "Put the black bowl in the sink."                                                                                                                                                                        | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                                  | [{'link': 'gs://gresearch/robotics/jaco_play/0.1.0', 'source': 'google_bucket'}]                                                     | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 976}, {'test': 109}]      |         9.24 |
| Berkeley Autolab UR5            | The data consists of 4 robot manipulation tasks: simple pick-and-place of a stuffed animal between containers, sweeping a cloth, stacking cups, and a more difficult pick-and-place of a bottle that requires precise grasp and 6DOF rotation                                                                                                       | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/berkeley_autolab_ur5/0.1.0', 'source': 'google_bucket'}]                                          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 896}, {'test': 104}]      |        76.39 |
| Austin VIOLA                    | The robot performs various household-like tasks, such as setting up the table, or making coffee using a coffee machine.                                                                                                                                                                                                                             | ['Open-X-Embodiment', 'Single Arm', 'Human Spacemouse', 'Scene:Table Top']                                                                                                                                                              | [{'link': 'gs://gresearch/robotics/viola/0.1.0', 'source': 'google_bucket'}]                                                         | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 135}, {'test': 15}]       |        10.4  |
| SPOC                            | The robot navigates in the environment and performs pick and place with open vocabulary descriptions.                                                                                                                                                                                                                                               | ['Open-X-Embodiment', 'Single Arm', 'Scripted', 'Scene:Kitchen', 'Scene:Other Household environments', 'Scene:Hallways', 'Scene:multi room environments']                                                                               | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |       765    |
| TOTO Benchmark                  | The TOTO Benchmark Dataset contains trajectories of two tasks: scooping and pouring. For scooping, the objective is to scoop material from a bowl into the spoon. For pouring, the goal is to pour some material into a target cup on the table.                                                                                                    | ['Open-X-Embodiment', 'Single Arm', 'The dataset is collected in 3 ways: Human teleoperation -- VR Teleop, trained state-based BC policies, and trajectory replay with noise', 'Scene:Table Top']                                       | [{'link': 'gs://gresearch/robotics/toto/0.1.0', 'source': 'google_bucket'}]                                                          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 902}, {'test': 101}]      |       127.66 |
| RT-1 Robot Action               | Robot picks, places and moves 17 objects from the google micro kitchens.                                                                                                                                                                                                                                                                            | ['Open-X-Embodiment', 'Mobile Manipulator', 'Human VR', 'Scene:Table Top', 'Scene:Kitchen (also toy kitchen)']                                                                                                                          | [{'link': 'gs://gresearch/robotics/fractal20220817_data/0.1.0', 'source': 'google_bucket'}]                                          | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 87212}]                   |       111.06 |
| Plex RoboSuite                  | Opening a door, stacking 2 cubes, picking and placing various objects to specially designated areas, putting a loop onto a peg.                                                                                                                                                                                                                     | ['Open-X-Embodiment', 'Single Arm', 'Human Keyboard', 'Scene:Table Top', 'Scene:Tabletop with sections']                                                                                                                                | []                                                                                                                                   | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 3331523}, {'test': 3774}] |         1.26 |
| Roboturk                        | Sawyer robots flattens laundry, builds towers from bowls and searches objects.                                                                                                                                                                                                                                                                      | ['Open-X-Embodiment', 'Single Arm', 'Human VR', 'Scene:Table Top']                                                                                                                                                                      | [{'link': 'gs://gresearch/robotics/roboturk/0.1.0', 'source': 'google_bucket'}]                                                      | [{'open_x_embodiment': True}] |                             | Copyright   | [{'train': 1796}, {'test': 199}]     |        45.39 |

## Contributing

Explain how to contribute here.
    